
name: CS2 → Discord (All Tasks)

on:
  schedule:
    - cron: '30 13 * * *'     # 9:30 AM ET daily summary (portfolio)
    - cron: '0 */2 * * *'     # every 2 hours: pumps + investment + alerts
    - cron: '0 13,22 * * *'   # 9 AM & 6 PM ET approx: cases/souvenirs + stickers/patches
  workflow_dispatch:

jobs:
  run:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout (dummy)
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Write scripts
        shell: bash
        run: |
          cat > cs2_portfolio_to_discord.py << 'PY'

import csv
import os
import sys
import io
import json
from datetime import datetime, timezone
from urllib.request import urlopen, Request

CSV_URL = os.environ.get("CSV_URL", "https://docs.google.com/spreadsheets/d/e/2PACX-1vRT72XsOKNZj_RRIhkJ-sNs_aWkfhAMMYd9sv6dAL7Cdu8wGI704fw9aFtRlQtKow/pub?output=csv")
DISCORD_WEBHOOK_URL = os.environ.get("DISCORD_WEBHOOK_URL")
RUN_MODE = os.environ.get("RUN_MODE", "summary")  # "summary" or "alerts"
ALERT_UP_THRESHOLD = float(os.environ.get("ALERT_UP_THRESHOLD", "0.10"))
ALERT_DOWN_THRESHOLD = float(os.environ.get("ALERT_DOWN_THRESHOLD", "-0.10"))
STATE_FILE = os.environ.get("STATE_FILE", "last_prices.json")

REQUIRED_HEADERS = [
    "Item Name","Condition","Quantity","Buy Price (USD)","Buy Date",
    "Current Price (USD)","Current Value (USD)","Unrealized Profit (USD)","ROI (%)"
]

def fetch_csv(url: str):
    req = Request(url, headers={"User-Agent": "Mozilla/5.0"})
    with urlopen(req, timeout=30) as r:
        data = r.read()
    return data.decode("utf-8")

def parse_csv(text: str):
    reader = csv.DictReader(io.StringIO(text))
    headers = [h.strip() for h in reader.fieldnames or []]
    for req in REQUIRED_HEADERS:
        if req not in headers:
            raise ValueError(f"Missing required header: {req}")
    rows = []
    for row in reader:
        norm = {k.strip(): v for k, v in row.items()}
        rows.append(norm)
    return rows

def to_float(x, default=0.0):
    try:
        if isinstance(x, str):
            x = x.strip().replace(",","")
        return float(x)
    except Exception:
        return default

def summarise(rows):
    total_current_value = 0.0
    total_cost_basis = 0.0

    roi_list = []

    for r in rows:
        qty = to_float(r.get("Quantity", 0), 0.0)
        buy_price = to_float(r.get("Buy Price (USD)", 0), 0.0)
        current_price = to_float(r.get("Current Price (USD)", 0), 0.0)

        current_value = qty * current_price
        total_current_value += current_value
        total_cost_basis += qty * buy_price

        # Prefer explicit ROI column; if missing/blank, compute from buy/current
        roi_cell = str(r.get("ROI (%)","")).replace("%","").strip()
        roi_percent = None
        if roi_cell:
            try:
                roi_percent = float(roi_cell)
            except Exception:
                roi_percent = None
        if roi_percent is None and buy_price > 0:
            roi_percent = (current_price - buy_price) / buy_price * 100

        roi_list.append({
            "item": r.get("Item Name",""),
            "condition": r.get("Condition",""),
            "roi": roi_percent if roi_percent is not None else 0.0,
            "current_price": current_price
        })

    unrealized = total_current_value - total_cost_basis
    roi_pct = (unrealized/total_cost_basis*100) if total_cost_basis>0 else 0.0

    roi_list_clean = [x for x in roi_list if x["roi"] is not None]
    gainers = sorted(roi_list_clean, key=lambda x: x["roi"], reverse=True)[:5]
    losers = sorted(roi_list_clean, key=lambda x: x["roi"])[:5]

    return {
        "total_current_value": total_current_value,
        "total_cost_basis": total_cost_basis,
        "unrealized": unrealized,
        "roi_pct": roi_pct,
        "gainers": gainers,
        "losers": losers,
    }

def load_state(path):
    try:
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception:
        return {}

def save_state(path, data):
    with open(path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

def compute_alerts(rows, last_state):
    alerts = []
    new_state = {}

    def key_for(r):
        return f"{r.get('Item Name','')} | {r.get('Condition','')}"

    for r in rows:
        key = key_for(r)
        current_price = to_float(r.get("Current Price (USD)",0),0.0)
        new_state[key] = current_price

        prev_price = last_state.get(key)
        if prev_price and prev_price > 0:
            pct_change = (current_price - prev_price)/prev_price
            if pct_change >= ALERT_UP_THRESHOLD or pct_change <= ALERT_DOWN_THRESHOLD:
                alerts.append({
                    "key": key,
                    "prev": prev_price,
                    "curr": current_price,
                    "pct": pct_change*100
                })

    return alerts, new_state

def post_to_discord(webhook_url, content=None, embed=None):
    import json, urllib.request
    payload = {}
    if content:
        payload["content"] = content
    if embed:
        payload["embeds"] = [embed]
    data = json.dumps(payload).encode("utf-8")
    req = urllib.request.Request(webhook_url, data=data, headers={"Content-Type": "application/json"})
    with urllib.request.urlopen(req, timeout=30) as resp:
        resp.read()

def fmt_money(x):
    return f"${x:,.2f}"

def main():
    if not DISCORD_WEBHOOK_URL:
        print("ERROR: DISCORD_WEBHOOK_URL not set", file=sys.stderr)
        sys.exit(2)

    # Fetch & parse
    try:
        csv_text = fetch_csv(CSV_URL)
        rows = parse_csv(csv_text)
    except Exception as e:
        post_to_discord(DISCORD_WEBHOOK_URL, content=f"⚠️ Portfolio fetch error: {e}")
        sys.exit(1)

    now = datetime.now(timezone.utc).astimezone().strftime("%b %d, %Y %I:%M %p %Z")

    if RUN_MODE.lower() == "summary":
        summary = summarise(rows)

        def list_block(items):
            if not items:
                return "_None_"
            lines = []
            for x in items:
                lines.append(f"- **{x['item']}** ({x['condition']}): {x['roi']:.2f}%")
            return "\n".join(lines)

        embed = {
            "title": f"💼 CS2 Portfolio Summary — {now}",
            "description": "Daily summary from your Google Sheet",
            "fields": [
                {"name":"Total Current Value","value": fmt_money(summary["total_current_value"]), "inline": True},
                {"name":"Total Cost Basis","value": fmt_money(summary["total_cost_basis"]), "inline": True},
                {"name":"Unrealized P&L","value": fmt_money(summary["unrealized"]), "inline": True},
                {"name":"ROI %","value": f"{summary['roi_pct']:.2f}%", "inline": True},
                {"name":"Top 5 Gainers (ROI %)","value": list_block(summary["gainers"]), "inline": False},
                {"name":"Top 5 Losers (ROI %)","value": list_block(summary["losers"]), "inline": False},
            ],
            "footer": {"text":"Source: Published CSV portfolio"},
        }
        post_to_discord(DISCORD_WEBHOOK_URL, embed=embed)
        return

    # Alerts
    last = load_state(STATE_FILE)
    alerts, new_state = compute_alerts(rows, last)
    save_state(STATE_FILE, new_state)

    if alerts:
        lines = []
        for a in alerts:
            arrow = "▲" if a["pct"]>0 else "▼"
            lines.append(f"{arrow} **{a['key']}** {a['pct']:.1f}%  ({fmt_money(a['prev'])} → {fmt_money(a['curr'])})")
        content = "🚨 **Intraday Price Alerts** (since last run)\n" + "\n".join(lines)
        post_to_discord(DISCORD_WEBHOOK_URL, content=content)
    else:
        post_to_discord(DISCORD_WEBHOOK_URL, content="✅ No intraday price alerts this run.")

if __name__ == "__main__":
    main()

PY
          cat > pump_dump_scanner.py << 'PY'

import os, json, sys, time
from datetime import datetime, timezone
from urllib.request import Request, urlopen
import urllib.error

DISCORD_WEBHOOK_URL = os.environ.get("DISCORD_WEBHOOK_URL")
TITLE_PREFIX = os.environ.get("TITLE_PREFIX", "CS2 Alert")
TZ_NAME = time.tzname[0] if time.tzname else "Local"

def post_discord(embed=None, content=None):
    import urllib.request
    payload = {}
    if content: payload["content"] = content
    if embed: payload["embeds"] = [embed]
    data = json.dumps(payload).encode("utf-8")
    req = urllib.request.Request(DISCORD_WEBHOOK_URL, data=data, headers={"Content-Type":"application/json"})
    with urllib.request.urlopen(req, timeout=30) as r: r.read()

def fetch_json(url):
    req = Request(url, headers={"User-Agent":"Mozilla/5.0"})
    with urlopen(req, timeout=30) as r:
        return json.loads(r.read().decode("utf-8"))


# Expected ENV:
# PUMP_FEED_URL: JSON endpoint returning an array of {item, wear, stattrak, pct24, pct72, volume_note, links:[...]}.
# If you don't have a feed yet, set PUMP_FEED_URL to a temporary JSON (e.g., a GitHub raw gist) that you update.

PUMP_FEED_URL = os.environ.get("PUMP_FEED_URL")  # e.g., your own feed or aggregator
THRESH24 = float(os.environ.get("PUMP_THRESH24", "25"))   # %
THRESH72 = float(os.environ.get("PUMP_THRESH72", "40"))   # %

def main():
    if not DISCORD_WEBHOOK_URL:
        print("Missing DISCORD_WEBHOOK_URL", file=sys.stderr); sys.exit(2)
    now = datetime.now(timezone.utc).astimezone().strftime("%b %d, %Y %I:%M %p %Z")
    if not PUMP_FEED_URL:
        post_discord(content="⚠️ Pump scanner: No PUMP_FEED_URL configured.")
        return
    try:
        items = fetch_json(PUMP_FEED_URL)
    except Exception as ex:
        post_discord(content=f"⚠️ Pump scanner fetch error: {ex}")
        return
    flagged = []
    for x in items:
        p24 = float(x.get("pct24", 0))
        p72 = float(x.get("pct72", 0))
        if p24 >= THRESH24 or p72 >= THRESH72:
            flagged.append(x)
    if not flagged:
        post_discord(content=f"✅ No pump-like moves this run ({now}).")
        return
    lines = []
    for x in flagged[:12]:
        name = x.get("item","?")
        wear = x.get("wear","")
        st = " ST" if x.get("stattrak") else ""
        p24 = x.get("pct24","?")
        p72 = x.get("pct72","?")
        vol = x.get("volume_note","")
        link = (x.get("links") or [""])[0]
        lines.append(f"• **{name}** ({wear}{st}) — 24h: +{p24}%, 72h: +{p72}% {('· '+vol) if vol else ''} {link}")
    embed = {
        "title": f"🚨 Pump-like Moves — {now}",
        "description": "\n".join(lines) or "_None_",
        "footer": { "text": "Sources: Steam · CSFloat · BUFF163 (+ CN buzz if available)" }
    }
    post_discord(embed=embed)

if __name__ == "__main__":
    main()

PY
          cat > investment_grade_scanner.py << 'PY'

import os, json, sys, time
from datetime import datetime, timezone
from urllib.request import Request, urlopen
import urllib.error

DISCORD_WEBHOOK_URL = os.environ.get("DISCORD_WEBHOOK_URL")
TITLE_PREFIX = os.environ.get("TITLE_PREFIX", "CS2 Alert")
TZ_NAME = time.tzname[0] if time.tzname else "Local"

def post_discord(embed=None, content=None):
    import urllib.request
    payload = {}
    if content: payload["content"] = content
    if embed: payload["embeds"] = [embed]
    data = json.dumps(payload).encode("utf-8")
    req = urllib.request.Request(DISCORD_WEBHOOK_URL, data=data, headers={"Content-Type":"application/json"})
    with urllib.request.urlopen(req, timeout=30) as r: r.read()

def fetch_json(url):
    req = Request(url, headers={"User-Agent":"Mozilla/5.0"})
    with urlopen(req, timeout=30) as r:
        return json.loads(r.read().decode("utf-8"))


# Expected ENV:
# INVEST_FEED_URL: JSON array of objects with {item, reason, trend7, trend30, listings_change, supply_note, links:[...]}.

INVEST_FEED_URL = os.environ.get("INVEST_FEED_URL")

def main():
    if not DISCORD_WEBHOOK_URL:
        print("Missing DISCORD_WEBHOOK_URL", file=sys.stderr); sys.exit(2)
    now = datetime.now(timezone.utc).astimezone().strftime("%b %d, %Y %I:%M %p %Z")
    if not INVEST_FEED_URL:
        post_discord(content="⚠️ Investment-grade scanner: No INVEST_FEED_URL configured.")
        return
    try:
        items = fetch_json(INVEST_FEED_URL)
    except Exception as ex:
        post_discord(content=f"⚠️ Investment-grade fetch error: {ex}")
        return
    lines = []
    for x in items[:10]:
        name = x.get("item","?")
        r = x.get("reason","signal")
        t7 = x.get("trend7","?")
        t30 = x.get("trend30","?")
        lst = x.get("listings_change","")
        sup = x.get("supply_note","")
        link = (x.get("links") or [""])[0]
        lines.append(f"• **{name}** — 7d: {t7}, 30d: {t30}  · {lst}  · {sup}  {link}")
    embed = {
        "title": f"🔎 Early Investment-Grade Candidates — {now}",
        "description": "\n".join(lines) or "_No candidates_",
        "footer": { "text": "Signals: Trend + Volume + Listings + Supply + Buzz" }
    }
    post_discord(embed=embed)

if __name__ == "__main__":
    main()

PY
          cat > cases_souvenirs_report.py << 'PY'

import os, json, sys, time
from datetime import datetime, timezone
from urllib.request import Request, urlopen
import urllib.error

DISCORD_WEBHOOK_URL = os.environ.get("DISCORD_WEBHOOK_URL")
TITLE_PREFIX = os.environ.get("TITLE_PREFIX", "CS2 Alert")
TZ_NAME = time.tzname[0] if time.tzname else "Local"

def post_discord(embed=None, content=None):
    import urllib.request
    payload = {}
    if content: payload["content"] = content
    if embed: payload["embeds"] = [embed]
    data = json.dumps(payload).encode("utf-8")
    req = urllib.request.Request(DISCORD_WEBHOOK_URL, data=data, headers={"Content-Type":"application/json"})
    with urllib.request.urlopen(req, timeout=30) as r: r.read()

def fetch_json(url):
    req = Request(url, headers={"User-Agent":"Mozilla/5.0"})
    with urlopen(req, timeout=30) as r:
        return json.loads(r.read().decode("utf-8"))


# Expected ENV:
# CASES_FEED_URL: JSON array of {name, chg24, chg72, chg7d, direction24, direction72, direction7d, notes, links:[...]}.

CASES_FEED_URL = os.environ.get("CASES_FEED_URL")

def main():
    if not DISCORD_WEBHOOK_URL:
        print("Missing DISCORD_WEBHOOK_URL", file=sys.stderr); sys.exit(2)
    now = datetime.now(timezone.utc).astimezone().strftime("%b %d, %Y %I:%M %p %Z")
    if not CASES_FEED_URL:
        post_discord(content="⚠️ Cases/Souvenirs: No CASES_FEED_URL configured.")
        return
    try:
        items = fetch_json(CASES_FEED_URL)
    except Exception as ex:
        post_discord(content=f"⚠️ Cases/Souvenirs fetch error: {ex}")
        return

    up = []; down = []
    for x in items:
        row = f"• **{x.get('name','?')}** — 24h: {x.get('chg24','?')} / 72h: {x.get('chg72','?')} / 7d: {x.get('chg7d','?')}  {x.get('notes','')} {(x.get('links') or [''])[0]}"
        if x.get("direction24") == "UP" or x.get("direction72") == "UP" or x.get("direction7d") == "UP":
            up.append(row)
        if x.get("direction24") == "DOWN" or x.get("direction72") == "DOWN" or x.get("direction7d") == "DOWN":
            down.append(row)

    embed = {
        "title": f"📦 Cases & Souvenirs — {now}",
        "fields": [
            {"name":"UPWARD Movers (24h/72h/7d)","value": "\n".join(up) or "_None_", "inline": False},
            {"name":"DOWNWARD Movers (24h/72h/7d)","value": "\n".join(down) or "_None_", "inline": False},
        ],
        "footer": { "text": "Cross-ref stickers/patches when applicable" }
    }
    post_discord(embed=embed)

if __name__ == "__main__":
    main()

PY
          cat > stickers_patches_report.py << 'PY'

import os, json, sys, time
from datetime import datetime, timezone
from urllib.request import Request, urlopen
import urllib.error

DISCORD_WEBHOOK_URL = os.environ.get("DISCORD_WEBHOOK_URL")
TITLE_PREFIX = os.environ.get("TITLE_PREFIX", "CS2 Alert")
TZ_NAME = time.tzname[0] if time.tzname else "Local"

def post_discord(embed=None, content=None):
    import urllib.request
    payload = {}
    if content: payload["content"] = content
    if embed: payload["embeds"] = [embed]
    data = json.dumps(payload).encode("utf-8")
    req = urllib.request.Request(DISCORD_WEBHOOK_URL, data=data, headers={"Content-Type":"application/json"})
    with urllib.request.urlopen(req, timeout=30) as r: r.read()

def fetch_json(url):
    req = Request(url, headers={"User-Agent":"Mozilla/5.0"})
    with urlopen(req, timeout=30) as r:
        return json.loads(r.read().decode("utf-8"))


# Expected ENV:
# STICKERS_FEED_URL: JSON array of {name, chg24, chg72, chg7d, direction24, direction72, direction7d, notes, links:[...]}.

STICKERS_FEED_URL = os.environ.get("STICKERS_FEED_URL")

def main():
    if not DISCORD_WEBHOOK_URL:
        print("Missing DISCORD_WEBHOOK_URL", file=sys.stderr); sys.exit(2)
    now = datetime.now(timezone.utc).astimezone().strftime("%b %d, %Y %I:%M %p %Z")
    if not STICKERS_FEED_URL:
        post_discord(content="⚠️ Stickers/Patches: No STICKERS_FEED_URL configured.")
        return
    try:
        items = fetch_json(STICKERS_FEED_URL)
    except Exception as ex:
        post_discord(content=f"⚠️ Stickers/Patches fetch error: {ex}")
        return

    up = []; down = []
    for x in items:
        row = f"• **{x.get('name','?')}** — 24h: {x.get('chg24','?')} / 72h: {x.get('chg72','?')} / 7d: {x.get('chg7d','?')}  {x.get('notes','')} {(x.get('links') or [''])[0]}"
        if x.get("direction24") == "UP" or x.get("direction72") == "UP" or x.get("direction7d") == "UP":
            up.append(row)
        if x.get("direction24") == "DOWN" or x.get("direction72") == "DOWN" or x.get("direction7d") == "DOWN":
            down.append(row)

    embed = {
        "title": f"🎟️ Stickers & Patches — {now}",
        "fields": [
            {"name":"UPWARD Movers (24h/72h/7d)","value": "\n".join(up) or "_None_", "inline": False},
            {"name":"DOWNWARD Movers (24h/72h/7d)","value": "\n".join(down) or "_None_", "inline": False},
        ],
        "footer": { "text": "Cross-ref cases/souvenirs when applicable" }
    }
    post_discord(embed=embed)

if __name__ == "__main__":
    main()

PY

      - name: Daily Portfolio Summary
        if: ${ github.event.schedule == '30 13 * * *' }
        env:
          CSV_URL: ${ secrets.CSV_URL }
          DISCORD_WEBHOOK_URL: ${ secrets.DISCORD_WEBHOOK_URL }
          RUN_MODE: summary
        run: python cs2_portfolio_to_discord.py

      - name: Intraday Portfolio Alerts (every 2h)
        if: ${ github.event.schedule == '0 */2 * * *' }
        env:
          CSV_URL: ${ secrets.CSV_URL }
          DISCORD_WEBHOOK_URL: ${ secrets.DISCORD_WEBHOOK_URL }
          RUN_MODE: alerts
        run: python cs2_portfolio_to_discord.py

      - name: Pump Scanner (every 2h)
        if: ${ github.event.schedule == '0 */2 * * *' }
        env:
          DISCORD_WEBHOOK_URL: ${ secrets.DISCORD_WEBHOOK_URL }
          PUMP_FEED_URL: ${ secrets.PUMP_FEED_URL }
          PUMP_THRESH24: "25"
          PUMP_THRESH72: "40"
        run: python pump_dump_scanner.py

      - name: Early Investment-Grade Scanner (every 2h)
        if: ${ github.event.schedule == '0 */2 * * *' }
        env:
          DISCORD_WEBHOOK_URL: ${ secrets.DISCORD_WEBHOOK_URL }
          INVEST_FEED_URL: ${ secrets.INVEST_FEED_URL }
        run: python investment_grade_scanner.py

      - name: Cases & Souvenirs (9 AM & 6 PM ET approx)
        if: ${ github.event.schedule == '0 13,22 * * *' }
        env:
          DISCORD_WEBHOOK_URL: ${ secrets.DISCORD_WEBHOOK_URL }
          CASES_FEED_URL: ${ secrets.CASES_FEED_URL }
        run: python cases_souvenirs_report.py

      - name: Stickers & Patches (9 AM & 6 PM ET approx)
        if: ${ github.event.schedule == '0 13,22 * * *' }
        env:
          DISCORD_WEBHOOK_URL: ${ secrets.DISCORD_WEBHOOK_URL }
          STICKERS_FEED_URL: ${ secrets.STICKERS_FEED_URL }
        run: python stickers_patches_report.py
